{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A working machine learning example\n",
    "In this notebook, we'll examine a dataset and create a predictive model, or ensemble of models, to predict the output for unseen data points.\n",
    "\n",
    "We will use the output of the FizzBuzz program and 'reverse engineer' the program using data analysis and machine learning. So, in the end, our model should be capable of predicting the output of the FizzBuzz program for a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we use pandas for data analysis and plotting\n",
    "import pandas as pd\n",
    "# seaborn provides enhanced visualization functionality\n",
    "import seaborn as sns\n",
    "# Spark's mllib provides machine learning functionality\n",
    "from pyspark.mllib.tree import LabeledPoint, RandomForest, RandomForestModel\n",
    "from pyspark.mllib.regression import LinearRegressionWithSGD, RidgeRegressionWithSGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn\n",
    "Note: this notebook uses the seaborn package for visualization, see [Gallery](http://web.stanford.edu/~mwaskom/software/seaborn/examples/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd = (\n",
    "    sc\n",
    "    .textFile('fizzbuzz.csv')                     # read textfile\n",
    "    .map(lambda line: line.strip().split(','))    # parse CSV into two fields\n",
    "    .map(lambda (n, fb): (int(n), fb))            # parse first element as int\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "It is generally a good idea to count the number of samples in your dataset, to ensure that it loaded properly and that there are no obvious errors at first sight. Also, you'll want to just eyeball the data to have a look at the values in there and get a better feeling for what different columns might mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rdd.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers vs. the rest\n",
    "In this example, the target is to predict the second column of the data (fizzbuzz) based on the first column (the number input). It appears that the output is a string which can either be a number or some label: Fizz, Buzz or FizzBuzz. Let us verify that this is the case. We'll split the data into two parts based on the output:\n",
    "- the numbers\n",
    "- the rest (textual output)\n",
    "\n",
    "Using this split and subsequent analysis, we might gain insight into what causes the output to be either a number or something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_int(x):\n",
    "    try:\n",
    "        int(x)\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_numbers = rdd.filter(lambda (n, fb): not is_int(fb)) # Filter only values that are not an int\n",
    "not_numbers.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fizz, Buzz, FizzBuzz\n",
    "It once more appears that all the non-numerical output is either Fizz, Buzz or FizzBuzz and nothing else. Here, we verify this and count how often each of the labels occur. When working with a large dataset, we should always be careful when creating histograms like these and collecting them locally, as the result might be too large to collect locally in memory. Therefore, we first do a count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_numbers_hist = (\n",
    "    not_numbers\n",
    "    .map(lambda (n, fb): (fb, 1))       # Create tuples of (value, 1)\n",
    "    .reduceByKey(lambda x,y: x + y)     # Group by value and sum the 1's\n",
    ")\n",
    "not_numbers_hist.count()                # Find out how many classes there are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_numbers_hist.collect()              # Since there are only three classes, it's safe to collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 and 3 look important\n",
    "In the sample above with all the fizzes and buzzes, the apparent situation is that all input numbers that results in a text label are divisible by 3 or 5. We will try to incorporate this idea into a predictive model, by performing feature engineering: we create derived features from the original input feature. In this case, we will add a boolean feature that is True when the input is divisible by 3 and False otherwise. We do the same for 5.\n",
    "\n",
    "Note that at this point we do not verify whether our assumption about being divisible by 3 and 5 is complete and correct. If the assumed relation holds, the model will learn about it and the evaluation results will exhibit low error (later section). Otherwise, it's back to the drawing board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We create a DataFrame from a sample of the RDD of not_numbers\n",
    "not_number_frame = pd.DataFrame(\n",
    "    not_numbers\n",
    "    .sample(False, 0.01, 0)                # 1% sample\n",
    "    .map(lambda (n, fb): {                 # Turn into a collection of dict's\n",
    "        'n': n,\n",
    "        'fizzbuzz': fb,\n",
    "        'by_three': n % 3 == 0,            # Include engineered feature for divisibility by three\n",
    "        'by_five': n % 5 == 0              # Include engineered feature for divisibility by five\n",
    "        }).collect()                       # Collect the sample locally into the DataFrame\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's have a look\n",
    "not_number_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is the relation between divisibility by three and the outcome (in case of not a number)\n",
    "# Note: we use seaborn for visualization\n",
    "# What does it tell us?\n",
    "sns.barplot(not_number_frame.fizzbuzz, not_number_frame.by_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same for five\n",
    "sns.barplot(not_number_frame.fizzbuzz, not_number_frame.by_five)\n",
    "# What does it tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Same for divisibility by both\n",
    "not_number_frame['by_both'] = not_number_frame.by_three & not_number_frame.by_five\n",
    "sns.barplot(not_number_frame.fizzbuzz, not_number_frame.by_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions and numbers\n",
    "The three plot above show the absence or presence of label outputs (Fizz, Buzz or FizzBuzz) given the divisibility by either 3, 5 or both. What we see is that for different values for divisibility by 3 and 5, there exists a decision boundary between different label values. This should be effectively learned by decision trees.\n",
    "\n",
    "What remains is the part of the data where the result is not a label, but a numeric value. Let's further investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numbers = (\n",
    "    rdd\n",
    "    .filter(lambda (n, fb): is_int(fb))            # Filter only numbers (int's)\n",
    "    .map(lambda (n, fb): (n, int(fb)))             # Parse the string into an int if it is one\n",
    ")\n",
    "\n",
    "numbers_frame = pd.DataFrame(\n",
    "    numbers.sample(False, 0.01, 0).collect(),      # Take a 1% sample\n",
    "    columns=['n', 'fizzbuzz'])                     # Name the columns\n",
    "\n",
    "numbers_frame.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's look at the relation between n and the outcome\n",
    "numbers_frame.plot(kind='scatter', x='n', y='fizzbuzz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearity\n",
    "The relation between the input and output in the case of numbers appears perfectly linear (who would have thought?). This part of the data is better described by a linear regressor.\n",
    "\n",
    "## Modeling\n",
    "We conclude from the above analysis, that we can handle this prediction problem with a combination of two models using the following approach.\n",
    "\n",
    "For training:\n",
    "- Train a classification model (based on decision trees) on the part of the data with non-numeric output.\n",
    "- Train a regression model on the part of the data with numeric output.\n",
    "\n",
    "For prediction:\n",
    "- Make a prediction for the type of output (a textual label or numeric) using the classification model.\n",
    "- If the classification model predicts a label, predict the label.\n",
    "- If the classification model predicts a numeric output, use the regression model to predict the value.\n",
    "\n",
    "We will train both models and evaluate both models using a train/test split of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "We start out with the classification model. Here we use a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fizzbuzz_type(fb):\n",
    "    # Spark MLLib requires to encode everything into floats, even classes\n",
    "    return {\n",
    "        'Fizz': 1.0,\n",
    "        'Buzz': 2.0,\n",
    "        'FizzBuzz': 3.0\n",
    "    }.get(fb, 0.0)\n",
    "\n",
    "# create dataset\n",
    "classification_points = rdd.map(lambda (n, fb): LabeledPoint(fizzbuzz_type(fb), [n, n % 3 == 0, n % 5 == 0]))\n",
    "# split dataset into train- and test- set\n",
    "classification_points_train, classification_points_test = classification_points.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classification_model = RandomForest.trainClassifier(\n",
    "    classification_points_train,              # Use only the training part of the data\n",
    "    numClasses=4,                             # We can predict one of four classes\n",
    "    categoricalFeaturesInfo={1: 2, 2: 2},     # RandomForest needs to know which features are categorical\n",
    "    numTrees=3,\n",
    "    featureSubsetStrategy=\"auto\",\n",
    "    impurity='gini',\n",
    "    maxDepth=4,\n",
    "    maxBins=32)\n",
    "\n",
    "classifier_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model\n",
    "For predicting the numerical values we use a linear regressor with SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataset\n",
    "regression_points = numbers.map(lambda (n, fb): LabeledPoint(fb, [n]))\n",
    "# split dataset into train- and test- set\n",
    "regression_points_train, regression_points_test = regression_points.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regression_model = LinearRegressionWithSGD.train(\n",
    "    regression_points_train,   # Use only the training part of the data\n",
    "    iterations=100,\n",
    "    step=1.0,\n",
    "    initialWeights=[1.0]       # Little cheating here, but otherwise it won't converge on perfectly linear data.\n",
    ")\n",
    "\n",
    "regression_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "We will evaluate the two trained models separately. The final model should normally also be evaluated for fitness, but this is left as an exercise to the reader.\n",
    "\n",
    "We will use the [Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error) as evaluation metric. A perfect prediction would yield an error of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the Mean Squared Error between an RDD of predictions and an RDD of LabeledPoints with actuals.\n",
    "def MSE(predictions, test_data):\n",
    "    values_and_preds = test_data.map(lambda p: p.label).zip(predictions)\n",
    "    return values_and_preds.map(lambda (v, p): (v - p)**2).reduce(lambda x, y: x + y) / values_and_preds.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification MSE\n",
    "The MSE is actually not the standard way to evaluate a classifier. Do you know why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE(\n",
    "    classification_model.predict(classification_points_test.map(lambda p: p.features)),\n",
    "    classification_points_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MSE(\n",
    "    regression_points_test.map(lambda p: p.features).map(regression_model.predict),\n",
    "    regression_points_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction function\n",
    "Here we combine the two models as described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(n):\n",
    "    classification_features = [n, n % 3 == 0, n % 5 == 0]   # Features required by the classifier\n",
    "    regression_features = [x]                           # Features required by the regression\n",
    "    \n",
    "    # This is required to translate the floating point labels back to the original,\n",
    "    # since Spark requires floating point values as class labels.\n",
    "    classes = {\n",
    "        1.0: 'Fizz',\n",
    "        2.0: 'Buzz',\n",
    "        3.0: 'FizzBuzz'\n",
    "    }\n",
    "    \n",
    "    return classes.get(\n",
    "        classification_model.predict(classification_features),  # If the classifier gave us a textual output, use that\n",
    "        regression_model.predict(regression_features))  # Otherwise, use the regression model's prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final predictions\n",
    "Congratulations! We've machine learned FizzBuzz!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicted output\n",
    "[ predict(x) for x in range(1,21) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# original output\n",
    "rdd.take(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
