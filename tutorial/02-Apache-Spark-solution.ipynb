{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark exercise\n",
    "In this exercise, we'll work with Spark and the IPython notebook to load data from a file, process it and extract some information.\n",
    "\n",
    "Here are some important links / references:\n",
    "- [Spark documentation overview](https://spark.apache.org/documentation.html)\n",
    "- [Spark Python API](https://spark.apache.org/docs/latest/api/python/index.html) / [Python RDD API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD)\n",
    "- [Spark programming guide](https://spark.apache.org/docs/latest/programming-guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "In the current directory, you can find a CSV dump of the first 200000 (range 1...200001) numbers with their FizzBuzz output. Load this data into a RDD as a text file and count the number of lines it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fizzbuzz = sc.textFile('fizzbuzz.csv')\n",
    "fizzbuzz.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse the CSV\n",
    "Parse each line in the CSV into a tuple. Display the first 20 parsed tuples as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1', u'1'),\n",
       " (u'2', u'2'),\n",
       " (u'3', u'Fizz'),\n",
       " (u'4', u'4'),\n",
       " (u'5', u'Buzz'),\n",
       " (u'6', u'Fizz'),\n",
       " (u'7', u'7'),\n",
       " (u'8', u'8'),\n",
       " (u'9', u'Fizz'),\n",
       " (u'10', u'Buzz'),\n",
       " (u'11', u'11'),\n",
       " (u'12', u'Fizz'),\n",
       " (u'13', u'13'),\n",
       " (u'14', u'14'),\n",
       " (u'15', u'FizzBuzz'),\n",
       " (u'16', u'16'),\n",
       " (u'17', u'17'),\n",
       " (u'18', u'Fizz'),\n",
       " (u'19', u'19'),\n",
       " (u'20', u'Buzz')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = fizzbuzz.map(lambda line: tuple(line.strip().split(',')))\n",
    "parsed.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make histogram of Fizz, Buzz, FizzBuzz or number\n",
    "Count how often the values in the dataset are Fizz, Buzz, FizzBuzz or just a number. I.e. make a histogram of the types of values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'FizzBuzz', 13333), ('Number', 106667), (u'Fizz', 53333), (u'Buzz', 26667)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fizzbuzz_key(fb):\n",
    "    if fb == 'Fizz' or fb == 'Buzz' or fb == 'FizzBuzz':\n",
    "        return fb\n",
    "    else:\n",
    "        return 'Number'\n",
    "\n",
    "parsed\\\n",
    ".map(lambda (n, fb): (fizzbuzz_key(fb), 1))\\\n",
    ".reduceByKey(lambda x,y: x + y)\\\n",
    ".collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
